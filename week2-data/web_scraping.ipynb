{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "baec006d",
   "metadata": {},
   "source": [
    "# Web scraping - Beautiful Soup\n",
    "\n",
    "Web scraping is having a computer work with web pages through their html, css, etc.\n",
    "This is the only option for working with websites when there is no API or of the API does not give needed option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc40c612",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "response = requests.get(\"https://www.crummy.com/software/BeautifulSoup/bs4/doc\")\n",
    "\n",
    "# print(response.text)\n",
    "\n",
    "# Instance of bs\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "# Example, take all the paragraph tags\n",
    "print(soup.find_all(\"p\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87a433f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scrape images\n",
    "from IPython.display import Image, display\n",
    "\n",
    "response = requests.get(\"https://en.wikipedia.org/wiki/German_Shepherd\")\n",
    "\n",
    "soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "for img in soup.find_all(\"img\")[4:10]:\n",
    "    full_img = \"https:\" + img[\"src\"]\n",
    "    if full_img.endswith(\"jpg\"):\n",
    "        display(Image(full_img, width=100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a3a43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image\n",
    "Image(\n",
    "    \"https://upload.wikimedia.org/wikipedia/commons/thumb/d/d0/German_Shepherd_-_DSC_0346_%2810096362833%29.jpg/250px-German_Shepherd_-_DSC_0346_%2810096362833%29.jpg\",\n",
    "    width=100,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f472f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mimetypes\n",
    "\n",
    "def print_images(url, start=None, stop=None):\n",
    "    response = requests.get(url)\n",
    "\n",
    "    soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "\n",
    "    for img in soup.find_all(\"img\")[start:stop]:\n",
    "        if img[\"src\"].startswith(\"//\"):\n",
    "            full_img = \"https:\" + img[\"src\"]\n",
    "        else:\n",
    "            full_img = \"https://en.wikipedia.org\" + img[\"src\"]\n",
    "        mimetype = mimetypes.guess_type(full_img)\n",
    "        if mimetype[0] is None:\n",
    "            continue\n",
    "        if mimetype[0].startswith(\"image\"):\n",
    "            # Skip SVG images as IPython can't embed them\n",
    "            if mimetype[0] == \"image/svg+xml\":\n",
    "                print(f\"Skipping SVG image: {full_img}\")\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                display(Image(full_img, width=100))\n",
    "            except ValueError as e:\n",
    "                print(f\"Cannot display {full_img}: {e}\")\n",
    "\n",
    "url = input(\"Give me a web address: \")\n",
    "print(print_images(url))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python-mastery",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
